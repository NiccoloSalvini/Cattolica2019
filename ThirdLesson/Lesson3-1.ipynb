{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Introduction to Python\n",
    "================================\n",
    "\n",
    "Lesson 3 - Part1\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary \n",
    "\n",
    "In this lesson we will focus on Neural Network. The lesson is divided between an introduction an a technical part\n",
    "The topis that we'll cover are in the introduction are:\n",
    "\n",
    "  - Tensorflow\n",
    "  - Keras \n",
    "  \n",
    "For the technical part we will create some models for:\n",
    "\n",
    "  - Single class classification\n",
    "  - Multi class classification\n",
    "  - Custom model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Today there are many framework that allow to create a Neural Network, like:\n",
    "\n",
    "  - Tensorflow \n",
    "  - Theano\n",
    "  - Caffe\n",
    "  - MXNett\n",
    "  - CNTK\n",
    "  \n",
    "Among all of them, probabilly the most famous is Tensorflow.\n",
    "\n",
    "Considering the support, the community the resources available, Tensorflow is the engine chosen for this course.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tensorflow\n",
    "\n",
    "[Tensorflow](https://www.tensorflow.org/) it was originally developed by Google, now it's open source.\n",
    "\n",
    "The definition from the web site is the following:\n",
    "\n",
    "*TensorFlow™ is an open source software library for high performance numerical computation. Its flexible architecture allows easy deployment of computation across a variety of platforms (CPUs, GPUs, TPUs), and from desktops to clusters of servers to mobile and edge devices. Originally developed by researchers and engineers from the Google Brain team within Google’s AI organization, it comes with strong support for machine learning and deep learning and the flexible numerical computation core is used across many other scientific domains.*\n",
    "\n",
    "Google has deeply invested in this project, to the point that now in Google Cloud there are available some instances with GPU's (called TPU's) designed especially for TensorFlow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Keras\n",
    "\n",
    "In order to simply the definition of the Neural Network and to speed up the development time we'll not use TensorFlow directly.\n",
    "Instead we'll use [Keras](https://keras.io/).\n",
    "\n",
    "The definition from the website is the following:\n",
    "\n",
    "*Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "*\n",
    "\n",
    "As you can see from the description, Keras offers another advantage: with just a change of setting the same code can be used with:\n",
    "\n",
    "  - Tensorflow\n",
    "  - Theano\n",
    "  - CNTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow 2.0\n",
    "\n",
    "Tensorflow 2.0 has been released on September 30th 2019.\n",
    "\n",
    "The main new feature in this new relese in that Keras' API are now the official High Level APIs of Tensorflow, directly supported by the project itself.\n",
    "\n",
    "Quoting the home page of Keras:\n",
    "\n",
    "*At this time, we recommend that Keras users who use multi-backend Keras with the TensorFlow backend switch to tf.keras in TensorFlow 2.0. tf.keras is better maintained and has better integration with TensorFlow features (eager execution, distribution support and other).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparison between Keras and Tensorflow\n",
    "\n",
    "In order to undestand the advantage of using Keras, we will consider the code necessary to define the same network using TensorFlow directly or Keras.\n",
    "\n",
    "Before moving on we must remember what are the parameters involved with a neural network.\n",
    "\n",
    "Can you list me those parameters?\n",
    "\n",
    "  - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TensoFlow Multiclass\n",
    "\n",
    "Let's create a neural network to be used over the classic [mnsit](http://yann.lecun.com/exdb/mnist/) hand written digits with two hidden layer to classify samples in to the 10 possible classes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1027 20:08:25.664794 4713727424 deprecation.py:323] From <ipython-input-1-c3d55fec490c>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W1027 20:08:25.665626 4713727424 deprecation.py:323] From /Users/msaletta/anaconda3/envs/def/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W1027 20:08:25.666391 4713727424 deprecation.py:323] From /Users/msaletta/anaconda3/envs/def/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1027 20:08:25.876867 4713727424 deprecation.py:323] From /Users/msaletta/anaconda3/envs/def/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W1027 20:08:25.878925 4713727424 deprecation.py:323] From /Users/msaletta/anaconda3/envs/def/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "W1027 20:08:25.927705 4713727424 deprecation.py:323] From /Users/msaletta/anaconda3/envs/def/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "num_steps = 15\n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "# Create model\n",
    "def neural_net(x):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# Construct model\n",
    "logits = neural_net(X)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: mnist.test.images,\n",
    "                                      Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Keras Multiclass\n",
    "\n",
    "Let's create a neural network to be used over the classic [mnsit](http://yann.lecun.com/exdb/mnist/) hand written digits with two hidden layer to classify samples in to the 10 possible classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tf.keras.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "W1027 20:08:32.763258 4713727424 deprecation_wrapper.py:119] From /Users/msaletta/anaconda3/envs/def/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1027 20:08:32.764633 4713727424 deprecation_wrapper.py:119] From /Users/msaletta/anaconda3/envs/def/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1027 20:08:32.771802 4713727424 deprecation_wrapper.py:119] From /Users/msaletta/anaconda3/envs/def/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1027 20:08:32.852730 4713727424 deprecation_wrapper.py:119] From /Users/msaletta/anaconda3/envs/def/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1027 20:08:32.858536 4713727424 deprecation_wrapper.py:119] From /Users/msaletta/anaconda3/envs/def/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1027 20:08:33.025363 4713727424 deprecation.py:323] From /Users/msaletta/anaconda3/envs/def/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1027 20:08:33.070402 4713727424 deprecation_wrapper.py:119] From /Users/msaletta/anaconda3/envs/def/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "55000/55000 [==============================] - 4s 74us/step - loss: 0.2277 - acc: 0.9324 - val_loss: 0.1031 - val_acc: 0.9677\n",
      "Epoch 2/15\n",
      "55000/55000 [==============================] - 4s 65us/step - loss: 0.0826 - acc: 0.9740 - val_loss: 0.0775 - val_acc: 0.9744\n",
      "Epoch 3/15\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.0530 - acc: 0.9833 - val_loss: 0.0699 - val_acc: 0.9783\n",
      "Epoch 4/15\n",
      "55000/55000 [==============================] - 4s 72us/step - loss: 0.0407 - acc: 0.9872 - val_loss: 0.0785 - val_acc: 0.9768\n",
      "Epoch 5/15\n",
      "55000/55000 [==============================] - 4s 66us/step - loss: 0.0287 - acc: 0.9901 - val_loss: 0.0846 - val_acc: 0.9768\n",
      "Epoch 6/15\n",
      "55000/55000 [==============================] - 3s 60us/step - loss: 0.0257 - acc: 0.9919 - val_loss: 0.0668 - val_acc: 0.9823\n",
      "Epoch 7/15\n",
      "55000/55000 [==============================] - 4s 64us/step - loss: 0.0237 - acc: 0.9922 - val_loss: 0.0796 - val_acc: 0.9790\n",
      "Epoch 8/15\n",
      "55000/55000 [==============================] - 3s 61us/step - loss: 0.0167 - acc: 0.9944 - val_loss: 0.0787 - val_acc: 0.9807\n",
      "Epoch 9/15\n",
      "55000/55000 [==============================] - 4s 66us/step - loss: 0.0184 - acc: 0.9942 - val_loss: 0.0787 - val_acc: 0.9795\n",
      "Epoch 10/15\n",
      "55000/55000 [==============================] - 4s 67us/step - loss: 0.0143 - acc: 0.9952 - val_loss: 0.0743 - val_acc: 0.9831\n",
      "Epoch 11/15\n",
      "55000/55000 [==============================] - 4s 70us/step - loss: 0.0148 - acc: 0.9954 - val_loss: 0.0966 - val_acc: 0.9797\n",
      "Epoch 12/15\n",
      "55000/55000 [==============================] - 4s 68us/step - loss: 0.0168 - acc: 0.9947 - val_loss: 0.0763 - val_acc: 0.9813\n",
      "Epoch 13/15\n",
      "55000/55000 [==============================] - 4s 66us/step - loss: 0.0132 - acc: 0.9959 - val_loss: 0.0735 - val_acc: 0.9829\n",
      "Epoch 14/15\n",
      "55000/55000 [==============================] - 4s 65us/step - loss: 0.0091 - acc: 0.9972 - val_loss: 0.0935 - val_acc: 0.9805\n",
      "Epoch 15/15\n",
      "55000/55000 [==============================] - 4s 68us/step - loss: 0.0116 - acc: 0.9964 - val_loss: 0.0834 - val_acc: 0.9824\n",
      "10000/10000 [==============================] - 0s 27us/step\n",
      "\n",
      "acc: 98.24%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras as keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import advanced_activations\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 15\n",
    "batch_size = 128\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "#\n",
    "activationFun = 'relu'\n",
    "#activationFun = 'softmax'\n",
    "\n",
    "#Definition of the model type\n",
    "model = Sequential()\n",
    "#Definition of the layers\n",
    "model.add(Dense(num_input, input_dim=num_input,activation=activationFun))\n",
    "model.add(Dense(n_hidden_1,activation=activationFun))\n",
    "model.add(Dense(n_hidden_2,activation=activationFun))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "#Creation of the model\n",
    "adam = Adam(lr=learning_rate)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam,metrics=['accuracy'])\n",
    "#Fit of the network\n",
    "X = mnist.train.images\n",
    "Y = mnist.train.labels\n",
    "X_test = mnist.test.images\n",
    "Y_test = mnist.test.labels\n",
    "history = model.fit(X, Y, epochs=num_steps, batch_size=batch_size,validation_data=(X_test,Y_test))#validation_split=0.05\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Warning\n",
    "\n",
    "Keras is an API, so the implementation of function is not one to one with TensorFlow. Often similar parameters can bring to different results.\n",
    "\n",
    "**You have to optimize the network for Keras, not for Tensorflow**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analysis' Results\n",
    "\n",
    "If we take a closer look to the results of the network what we can see?\n",
    "\n",
    "During the fit of the model, with `history = model.fit`, we have stored in `history` all the values of **loss** and **accuracy** for train and test.\n",
    "\n",
    "Note that must pass some validation data or a validation split using `validation_data` or `validation_split` parameters in `model.fit` \n",
    "\n",
    "We can define these and other metrics to be use using the parameter `metrics` in `model.compile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.103131</td>\n",
       "      <td>0.9677</td>\n",
       "      <td>0.227736</td>\n",
       "      <td>0.932436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.077543</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.082579</td>\n",
       "      <td>0.974036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.069854</td>\n",
       "      <td>0.9783</td>\n",
       "      <td>0.053029</td>\n",
       "      <td>0.983291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.078492</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>0.040669</td>\n",
       "      <td>0.987182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.084636</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>0.028651</td>\n",
       "      <td>0.990091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.066813</td>\n",
       "      <td>0.9823</td>\n",
       "      <td>0.025690</td>\n",
       "      <td>0.991873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.079642</td>\n",
       "      <td>0.9790</td>\n",
       "      <td>0.023708</td>\n",
       "      <td>0.992218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.078690</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>0.016721</td>\n",
       "      <td>0.994400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.078716</td>\n",
       "      <td>0.9795</td>\n",
       "      <td>0.018360</td>\n",
       "      <td>0.994164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.074336</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.014342</td>\n",
       "      <td>0.995182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.096636</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.014802</td>\n",
       "      <td>0.995364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.076268</td>\n",
       "      <td>0.9813</td>\n",
       "      <td>0.016823</td>\n",
       "      <td>0.994691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.073535</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>0.013193</td>\n",
       "      <td>0.995927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.093525</td>\n",
       "      <td>0.9805</td>\n",
       "      <td>0.009111</td>\n",
       "      <td>0.997164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.083432</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.011617</td>\n",
       "      <td>0.996364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    val_loss  val_acc      loss       acc\n",
       "0   0.103131   0.9677  0.227736  0.932436\n",
       "1   0.077543   0.9744  0.082579  0.974036\n",
       "2   0.069854   0.9783  0.053029  0.983291\n",
       "3   0.078492   0.9768  0.040669  0.987182\n",
       "4   0.084636   0.9768  0.028651  0.990091\n",
       "5   0.066813   0.9823  0.025690  0.991873\n",
       "6   0.079642   0.9790  0.023708  0.992218\n",
       "7   0.078690   0.9807  0.016721  0.994400\n",
       "8   0.078716   0.9795  0.018360  0.994164\n",
       "9   0.074336   0.9831  0.014342  0.995182\n",
       "10  0.096636   0.9797  0.014802  0.995364\n",
       "11  0.076268   0.9813  0.016823  0.994691\n",
       "12  0.073535   0.9829  0.013193  0.995927\n",
       "13  0.093525   0.9805  0.009111  0.997164\n",
       "14  0.083432   0.9824  0.011617  0.996364"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAVlElEQVR4nO3df5BdZ33f8ffHEhAUiDFYoWBZuya4aU2aQNg4SZkynfDL+TE2bZxiunRMYEaTTgi0+dGYeCYWbtWBJEMpqdtECb+KN3GCCVTNJBgPJmlnGohXxpjY1EEYSZZr17JN+FERg+xv/zhH9tXqrLSy9tl7r/b9mrlz73nOuVffvdq9n/uc55znpKqQJGmpM8ZdgCRpMhkQkqRBBoQkaZABIUkaZEBIkgZtHHcBq+Xss8+u2dnZcZchSVNl9+7dD1TV5qF1p01AzM7Osri4OO4yJGmqJNm33Dp3MUmSBhkQkqRBBoQkaZABIUkaZEBIkgYZEAsLMDsLZ5zR3S8sjLsiSZoIp81hrk/IwgJs2waHDnXL+/Z1ywDz8+OrS5ImwPruQVx55ePhcMShQ127JK1z6zsg9u8/uXZJWkfWd0Bs3Xpy7ZK0jqzvgNixAzZtOrpt06auXZLWufUdEPPzsHMnzMxA0t3v3OkAtSSx3o9igi4MDARJOsb67kFIkpZlQEiSBhkQkqRBBoQkaZABIUkaZEBIkgYZEJKkQQaEJGmQASFJGmRASJIGGRCSpEEGhCRpkAEhSRpkQEiSBhkQkqRBBoQkaZABIUka1DQgklyU5M4ke5JcMbD+55PckeS2JJ9IMjOy7vIkX+hvl7esU5J0rGYBkWQDcA3wo8AFwGuTXLBks88Ac1X1vcD1wK/1z30mcBXwg8CFwFVJzmpVqyTpWC17EBcCe6rqrqr6JnAdcMnoBlX1yao61C9+CtjSP34VcGNVPVRVXwZuBC5qWKskaYmWAXEOcPfI8oG+bTlvBP70ZJ6bZFuSxSSLBw8ePMVyJUmjJmKQOsnrgDng10/meVW1s6rmqmpu8+bNbYqTpHWqZUDcA5w7srylbztKkpcDVwIXV9XDJ/NcSVI7LQPiZuD8JOcleTJwGbBrdIMkLwJ+my4c7h9ZdQPwyiRn9YPTr+zbJElrZGOrF66qw0neRPfBvgF4b1XdnuRqYLGqdtHtUnoa8KEkAPur6uKqeijJv6ULGYCrq+qhVrVKko6Vqhp3Datibm6uFhcXx12GJE2VJLuram5o3UQMUkuSJo8BIUkaZEBIkgYZEJKkQQaEJGmQASFJGmRASJIGGRCSpEEGhCRpkAEhSRpkQEiSBhkQkqRBBoQkaZABIUkaZEBIkgYZEJKkQQaEJGmQASFJGmRASJIGGRCSpEEGhCRpkAEhSRpkQEiSBhkQkqRBBoQkaZABIUkaZEBIkgYZEJKkQQaEJGmQASFJGmRASJIGGRCSpEEGhCRpkAEhSRpkQEiSBhkQkqRBTQMiyUVJ7kyyJ8kVA+tfmuSWJIeTXLpk3SNJbu1vu1rWKUk61sZWL5xkA3AN8ArgAHBzkl1VdcfIZvuB1wO/OPAS36iqF7aqT5J0fM0CArgQ2FNVdwEkuQ64BHgsIKpqb7/u0YZ1SJKegJa7mM4B7h5ZPtC3rdS3JVlM8qkkr17d0iRJJ9KyB3GqZqrqniTPA25K8rmq+uLoBkm2AdsAtm7dOo4aJem01bIHcQ9w7sjylr5tRarqnv7+LuDPgBcNbLOzquaqam7z5s2nVq0k6SgtA+Jm4Pwk5yV5MnAZsKKjkZKcleQp/eOzgZcwMnYhSWqvWUBU1WHgTcANwOeBP6yq25NcneRigCQ/kOQA8FPAbye5vX/63wcWk3wW+CTw9iVHP0mSGktVjbuGVTE3N1eLi4vjLkOSpkqS3VU1N7TOM6klSYMMCEnSIANCkjTIgJAkDTIgJEmDDAhJ0iADQpI0yICQJA0yICRJgwwISdIgA0KSNMiAkCQNMiAkSYMMCEnSIANCkjRoRQGR5LtGrvD2j5O8Ockz2pYmSRqnlfYgPgw8kuT5wE66a03/XrOqJEljt9KAeLS/hOg/AX6zqn4JeE67siRJ47bSgPhWktcClwN/3Lc9qU1JkqRJsNKA+Gngh4EdVfWlJOcBH2xXliRp3DauZKOqugN4M0CSs4CnV9U7WhYmSRqvlR7F9GdJviPJM4FbgN9J8s62pUmSxmmlu5jOrKqvAv8U+K9V9YPAy9uVJUkat5UGxMYkzwH+GY8PUkuSTmMrDYirgRuAL1bVzUmeB3yhXVmSpHFb6SD1h4APjSzfBfxkq6IkSeO30kHqLUk+kuT+/vbhJFtaFydJGp+V7mJ6H7ALeG5/++99myTpNLXSgNhcVe+rqsP97f3A5oZ1SZLGbKUB8WCS1yXZ0N9eBzzYsjBJ0nitNCDeQHeI633AvcClwOsb1SRJmgArCoiq2ldVF1fV5qr6zqp6NR7FJEmntVO5otzPr1oVkqSJcyoBkVWrQpI0cU4lIGrVqpgA27ePuwJJmizHDYgkX0vy1YHb1+jOhzhtvO1t465AkibLcafaqKqnr1UhkqTJciq7mE4oyUVJ7kyyJ8kVA+tfmuSWJIeTXLpk3eVJvtDfLm9R3/btkHS37t/sbu5ukiRIVZuhhCQbgL8GXgEcAG4GXttfne7INrPAdwC/COyqquv79mcCi8Ac3VjHbuDFVfXl5f69ubm5WlxcPIV6odFbIUkTK8nuqpobWteyB3EhsKeq7qqqbwLXAZeMblBVe6vqNuDRJc99FXBjVT3Uh8KNwEUNa5UkLdEyIM4B7h5ZPtC3rdpzk2xLsphk8eDBg0+4UICrrjqlp0s6AXfdTp+mYxCtVdXOqpqrqrnNm09t7kB/eaW2PFJw+rQMiHuAc0eWt/RtrZ8rSVoFLQPiZuD8JOcleTJwGd01JVbiBuCVSc5Kchbwyr5N0hTxSMGjTdvP3ewoJoAkPwa8C9gAvLeqdiS5Glisql1JfgD4CHAW8LfAfVX1gv65bwB+pX+pHVV13AsUnepRTJLa8kjByXwPjncUU9OAWEsGhDTZJvHDca1N4nswrsNcJekx6/VIwWnezWYPQpLWiD0ISdJpwYCQpDUybbvZDAhJWiPTMO4wyoBQc9P2RyGpY0C0sLAAs7Nwxhnd/cLCuCsaK6dYkNpq9SXMgFhtCwuwbRvs29cdrrBvX7e8zkNCUjutvoQZEKvtyivh0KGj2w4d6trXkWk+9ltSx4BYbfv3n1z7aWr79q4DdeSY7yOPJz0gJr0+6Yi1+BJmQKy2rVtPrn2C+OHYrqve6r31/2z9WosvYQbEatuxAzZtAmA7/UHPmzZ17ROu1YfjtB373UKr99YDANSSAbHa5udh506YmeFtbIeZmW55fn7clY3NpH/Ldbxkuvn/1O5LmAHRwvw87N3bPd67d6LDwQ/Hdl31Vu+t/2dHsxfV7v/eyfpW2fbtw7+wV101+X/AkziR2Fpr9R5M0+tu3z75v6uj/L09NU7Wt4am9egddRwvmY5v5GvRi/Jv1oDQCD8c230otHpv1+v/2Vp8EZuGoGzNgGho2v54/cbUzqQf5uq4hoYYEA1N+oeCdMQ07xpdzS9iBuXRHKSeQg7KqSV/vzrr5X1wkFrSik3brlG1Y0BMCbu+R1uvP/da8L3tGJTuYppK66Xrezy+B9LqcBeTJOmkGRBTaL12fd3NJq0tdzFpKrmLSVod7mKSJJ00A0JTab3uZpPWkgGhqeS4g9SeASFJGmRASJIGGRCSpEEGhCRpkAExTRYWYHYWzjiju19YGHdFkk5jG8ddgFZoYQG2bYNDh7rlffu6ZYD5+fHVJem0ZQ9iWlx55ePhcMShQ127JDXQNCCSXJTkziR7klwxsP4pSf6gX//pJLN9+2ySbyS5tb/9Vss6p8L+/SfXLkmnqNkupiQbgGuAVwAHgJuT7KqqO0Y2eyPw5ap6fpLLgHcAr+nXfbGqXtiqvqmzdWu3W2moXZIaaNmDuBDYU1V3VdU3geuAS5Zscwnwgf7x9cDLkiNzdeooO3bApk1Ht23a1LVLUgMtA+Ic4O6R5QN92+A2VXUY+ArwrH7deUk+k+TPk/yjoX8gybYki0kWDx48uLrVT5r5edi5E2ZmuqlMZ2a6ZQeoJTUyqUcx3QtsraoHk7wY+GiSF1TVV0c3qqqdwE7opvseQ51ra37eQJC0Zlr2IO4Bzh1Z3tK3DW6TZCNwJvBgVT1cVQ8CVNVu4IvA321YqyRpiZYBcTNwfpLzkjwZuAzYtWSbXcDl/eNLgZuqqpJs7ge5SfI84Hzgroa1SpKWaLaLqaoOJ3kTcAOwAXhvVd2e5Gpgsap2Ae8BPphkD/AQXYgAvBS4Osm3gEeBn6mqh1rVKkk6lpccVXeW9pVXdudUbN3aHRnlWIe0LhzvkqOTOkitteIUHpKW4VQb651TeEhahgGx3jmFh6RlGBDr3XJTdTiFh7TuGRDrnVN4SFqGAbHeOYWHpGV4FJOcwkPSIHsQkqRBBoQkaZABIUkaZEConYUFmJ2FM87o7hcWxl2RpJPgILXacAoPaerZg1AbTuEhTT0DQm20msLD3VbSmjEg1EaLKTyO7Lbatw+qHt9tZUhITRgQaqPFFB4td1vZM5GOYUCojRZTeLTcbWXPRDqGV5TT9Jid7T68l5qZgb17J+91pSlwvCvK2YPQ9Gg186zXxJAGGRCaHq1mnvWaGNIgA0LTZX6+2+3z6KPd/WqcdDeN18RwUF1rwICQWl4To8UHuYPqHUOyOQeppVaWTjcCXc/kVMPHQfV27+065CC1NA6tztuYtrPUW7yuU7msCQNCaqXVB/k0naXe6nVbHnnmrqvHGBBSK62Ojpqms9RbvW6r99bxnaMYEFIrrY6Omqaz1Fu9bqv3dtp2XbXu7VTVaXF78YtfXNLEufbaqpmZqqS7v/bacVc0bGamqvvOfPRtZmYyX7eqzXubDNebnPprr7Zrr63atOnoOjdtOun3AVisZT5Xx/7Bvlo3A0I6Bav0YbNmr9tKq0BrEWarVOvxAsJdTJLanQvS8hyTFlrsuprGgfqe50FI0qiFhW7MYf/+btB7x47JPG9llV7X8yAkaaVWezqXaRuoH2FASFJLrQ7JXYPddwaEJLXU8pt+i8krRxgQktTStA3Uj9g47gIk6bQ3Pz8VgbBU0x5EkouS3JlkT5IrBtY/Jckf9Os/nWR2ZN1b+/Y7k7yqZZ2SpGM1C4gkG4BrgB8FLgBem+SCJZu9EfhyVT0f+A/AO/rnXgBcBrwAuAj4z/3rSZLWSMsexIXAnqq6q6q+CVwHXLJkm0uAD/SPrwdeliR9+3VV9XBVfQnY07+eJGmNtAyIc4C7R5YP9G2D21TVYeArwLNW+FySbEuymGTx4MGDq1i6JGmqj2Kqqp1VNVdVc5s3bx53OZJ0Wml5FNM9wLkjy1v6tqFtDiTZCJwJPLjC5x5l9+7dDyQZOO98rM4GHhh3ESdhmuqdplphuuqdplphuuqdxFpnllvRMiBuBs5Pch7dh/tlwD9fss0u4HLgL4BLgZuqqpLsAn4vyTuB5wLnA395vH+sqiauC5Fkcbk5TibRNNU7TbXCdNU7TbXCdNU7TbVCw4CoqsNJ3gTcAGwA3ltVtye5mm562V3Ae4APJtkDPEQXIvTb/SFwB3AY+NmqeqRVrZKkYzU9Ua6q/gT4kyVtvzry+G+Bn1rmuTuA1Zt1SpJ0UqZ6kHoK7Bx3ASdpmuqdplphuuqdplphuuqdplpPn+tBSJJWlz0ISdIgA0KSNMiAaCDJuUk+meSOJLcnecu4azqRJBuSfCbJH4+7lhNJ8owk1yf530k+n+SHx13TcpL86/534K+S/H6Sbxt3TaOSvDfJ/Un+aqTtmUluTPKF/v6scdY4apl6f73/XbgtyUeSPGOcNR4xVOvIul9IUknOHkdtK2VAtHEY+IWqugD4IeBnByYqnDRvAT4/7iJW6D8CH6uqvwd8HxNad5JzgDcDc1X1PXSHe1823qqO8X66CTFHXQF8oqrOBz7RL0+K93NsvTcC31NV3wv8NfDWtS5qGe/n2FpJci7wSuAUrznangHRQFXdW1W39I+/RvcBdsxcUpMiyRbgx4HfHXctJ5LkTOCldOfQUFXfrKq/GW9Vx7UReGo/U8Am4P+MuZ6jVNX/oDsHadToJJofAF69pkUdx1C9VfXxfi43gE/Rzbwwdsu8t9DNXP1vgIk/QsiAaKy/xsWLgE+Pt5LjehfdL+yj4y5kBc4DDgLv63eJ/W6Sbx93UUOq6h7gN+i+Kd4LfKWqPj7eqlbk2VV1b//4PuDZ4yzmJL0B+NNxF7GcJJcA91TVZ8ddy0oYEA0leRrwYeBfVdVXx13PkCQ/AdxfVbvHXcsKbQS+H/gvVfUi4P8xWbtAHtPvu7+ELtSeC3x7kteNt6qTU91x8BP/TRcgyZV0u3cXxl3LkCSbgF8BfvVE204KA6KRJE+iC4eFqvqjcddzHC8BLk6yl+6aHT+S5NrxlnRcB4ADVXWkR3Y9XWBMopcDX6qqg1X1LeCPgH845ppW4v8meQ5Af3//mOs5oSSvB34CmK/JPbnru+i+LHy2/3vbAtyS5O+MtarjMCAa6C969B7g81X1znHXczxV9daq2lJVs3QDqDdV1cR+y62q+4C7k3x33/Qyujm7JtF+4IeSbOp/J17GhA6oL3FkEk36+/82xlpOKMlFdLtIL66qQ+OuZzlV9bmq+s6qmu3/3g4A39//Tk8kA6KNlwD/gu7b+K397cfGXdRp5OeAhSS3AS8E/v2Y6xnU93KuB24BPkf39zZRUy0k+X262ZS/O8mBJG8E3g68IskX6HpBbx9njaOWqfc/AU8Hbuz/1n5rrEX2lql1qjjVhiRpkD0ISdIgA0KSNMiAkCQNMiAkSYMMCEnSIANCOoEkj4wcrnxrklU7czvJ7NBsn9IkaHpNauk08Y2qeuG4i5DWmj0I6QlKsjfJryX5XJK/TPL8vn02yU399Qk+kWRr3/7s/noFn+1vR6bd2JDkd/rrRnw8yVP77d/cX1PktiTXjenH1DpmQEgn9tQlu5heM7LuK1X1D+jO5n1X3/abwAf66xMsAO/u298N/HlVfR/d/FG39+3nA9dU1QuAvwF+sm+/AnhR/zo/0+qHk5bjmdTSCST5elU9baB9L/AjVXVXPznjfVX1rCQPAM+pqm/17fdW1dlJDgJbqurhkdeYBW7sL85Dkl8GnlRV/y7Jx4CvAx8FPlpVX2/8o0pHsQchnZpa5vHJeHjk8SM8Pjb448A1dL2Nm/uLDklrxoCQTs1rRu7/on/8v3j80qLzwP/sH38C+Jfw2DXAz1zuRZOcAZxbVZ8Efhk4EzimFyO15DcS6cSemuTWkeWPVdWRQ13P6meVfRh4bd/2c3RXvPsluqvf/XTf/hZgZz+r5yN0YXEvwzYA1/YhEuDdE35pVZ2GHIOQnqB+DGKuqh4Ydy1SC+5ikiQNsgchSRpkD0KSNMiAkCQNMiAkSYMMCEnSIANCkjTo/wOeLbPaMQQMEgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "history_dict=history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'ro')\n",
    "plt.plot(epochs, val_loss_values, 'b+')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_values = history_dict['acc']\n",
    "val_loss_values = history_dict['val_acc']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'ro')\n",
    "plt.plot(epochs, val_loss_values, 'b+')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Keras Single Class\n",
    "\n",
    "Now we'll make an example of a binary classification task using Keras.\n",
    "\n",
    "The dataset is hosted on [Kaggle](https://www.kaggle.com/) and it's the [Promotion Response for a New Product](https://www.kaggle.com/regivm/promotion-response-and-target-datasets/version/1).\n",
    "\n",
    "The description of th dataset is the following:\n",
    "\n",
    "*The context of this business problem is new product introduction. A business organization developed a new product and promoted this to its existing customers. Initially it chose a sample of customers for promotion and the response information is available in the 'promoted' dataset. The organization is interested in building a model to select the best customers for contacting from the pool of customers not contacted ('target' dataset).*\n",
    "\n",
    "and the columns are:\n",
    "\n",
    "  - customer_id\n",
    "  - **res** (what we want to predict)\n",
    "  - card_tenure\n",
    "  - risk_score\n",
    "  - num_promoted\n",
    "  - avg_bal\n",
    "  - geo_group\n",
    "  - res_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Python Class \n",
    "\n",
    "To learn something new, we'll make the code of this model using Python classes.\n",
    "\n",
    "A **Class** is a blueprint for an object, that can contain variables and functions (called method).\n",
    "\n",
    "Please note similarity of our class with all what we have used so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import advanced_activations\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import preprocessing\n",
    "import logging\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger('')\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 15\n",
    "batch_size = 128\n",
    "n_fold = 5\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 25 # 1st layer number of neurons\n",
    "n_hidden_2 = 10 # 2nd layer number of neurons\n",
    "num_input = 6 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 1 # MNIST total classes (0-9 digits)\n",
    "\n",
    "trainFile = 'promoted.csv'\n",
    "predFile = 'target.csv'\n",
    "\n",
    "#\n",
    "activationFun = 'relu'\n",
    "#activationFun = 'softmax'\n",
    "\n",
    "class LoadData:\n",
    "    def __init__(self,**kargs):\n",
    "        self.path = 'data'\n",
    "        self.trainFile = kargs['tr']\n",
    "        \n",
    "    def readFiles(self,fileName):\n",
    "        fullPath = os.path.join(self.path,fileName)\n",
    "        logger.info('READING %s',fullPath)\n",
    "        df = pd.read_csv(fullPath,sep=',',dtype={'avg_bal':'category', 'geo_group':'category', 'res_type':'category',})#dtype={'avg_bal':'category', 'geo_group':'category', 'res_type':'category',}\n",
    "        logger.info('LOADED DATASET WITH SHAPE %s AND COLUMUNS %s',str(df.shape),str(df.columns))\n",
    "        print('After reading',df.describe())\n",
    "        return df\n",
    "        \n",
    "    def prepareTrain(self):\n",
    "        dfTrain = self.readFiles(self.trainFile)\n",
    "        logger.info('REMOVING ROWS WITH NA')\n",
    "        logger.info('NROWS BEFORE REMOVING NA %i',dfTrain.shape[0])\n",
    "        dfTrain.dropna(inplace=True)\n",
    "        logger.info('NROWS AFTER REMOVING NA %i',dfTrain.shape[0])\n",
    "        X_train = dfTrain.drop(columns=['resp','customer_id'])\n",
    "        Y_train = dfTrain.loc[:,'resp']\n",
    "        logger.info('SCALING OF NUMERIC COLUMNS')\n",
    "        mmscaler = preprocessing.MinMaxScaler()\n",
    "        X_train[['card_tenure', 'risk_score', 'num_promoted']] = mmscaler.fit_transform(X_train[['card_tenure', 'risk_score', 'num_promoted']])  \n",
    "        logger.info('CONSIDERING LEVELS FOR CATEGORICAL COLUMNS')\n",
    "        for curCol in ['avg_bal','geo_group', 'res_type']:\n",
    "            X_train[curCol] = dfTrain[curCol].cat.codes\n",
    "        logger.info('AFTER PREPROCESSING X_train HAS COLUMUNS %s AND TYPES %s',str(X_train.columns),str(X_train.dtypes))\n",
    "        return X_train, Y_train\n",
    "\n",
    "class CreateNN:\n",
    "    def __init__(self,**kargs):\n",
    "        self.X_train = kargs['xt']\n",
    "        self.Y_train = kargs['yt']\n",
    "        self.kFold = kargs['kf']\n",
    "        self.i = 1\n",
    "        \n",
    "    def modelDefinition(self):\n",
    "        logger.info('DEFINITION OF THE MODEL')\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(num_input, input_dim = num_input,activation=activationFun))\n",
    "        self.model.add(Dense(n_hidden_1,activation = activationFun))\n",
    "        self.model.add(Dense(n_hidden_2,activation = activationFun))\n",
    "        self.model.add(Dense(num_classes,activation = 'sigmoid'))\n",
    "        print(self.model.summary())\n",
    "    \n",
    "    def modelCompile(self):\n",
    "        logger.info('COMPILATION OF THE MODEL')\n",
    "        adam = Adam(lr = learning_rate)\n",
    "        self.model.compile(loss = 'binary_crossentropy', optimizer = adam,metrics = ['accuracy'])\n",
    "        \n",
    "    def modelEval(self):\n",
    "        logger.info('EVALUATION OF THE MODEL')\n",
    "        totalScores = list()\n",
    "        logger.info('START OF THE CROSS VALIDATION')\n",
    "        for train,test in self.kFold.split(self.X_train, self.Y_train):\n",
    "            logger.info('WORKING ON FOLD %i',self.i)\n",
    "            print('train set',train)\n",
    "            history = self.model.fit(self.X_train.iloc[train], self.Y_train.iloc[train],\n",
    "                                     epochs=num_steps, \n",
    "                                     batch_size = batch_size) #validation_data=(self.X_train.iloc[test], self.Y_train.iloc[test])\n",
    "            scores = self.model.evaluate(self.X_train.iloc[test], self.Y_train.iloc[test])\n",
    "            totalScores.append(scores[1])\n",
    "            self.i += 1\n",
    "        return history, self.model, totalScores\n",
    "    \n",
    "    def modelPredict(self):\n",
    "        self.model.predict(......)\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    #Inizialization of the class LoadData \n",
    "    logger.info('INIZIALIZATION OF LOADDATA')\n",
    "    ld = LoadData(tr=trainFile)\n",
    "    df2Pred = ld.readFiles(predFile)\n",
    "    X_train, Y_train = ld.prepareTrain()\n",
    "    kfold = StratifiedKFold(n_splits=n_fold)\n",
    "    logger.info('INIZIALIZATION OF CreateNN')\n",
    "    cnn = CreateNN(xt=X_train,yt=Y_train,kf=kfold)\n",
    "    cnn.modelDefinition()\n",
    "    cnn.modelCompile()\n",
    "    history, model, totalScores = cnn.modelEval() \n",
    "    logger.info('EVALUATION COMPLETED')\n",
    "    logger.info(\"FOR THE ACTUAL MODEL THE RESULTS OF %s IS: %.2f%%+/-%.2f%%\" % (model.metrics_names[1], np.mean(totalScores),np.std(totalScores)))\n",
    "    return X_train,Y_train, history,totalScores\n",
    "    \n",
    "X_train,Y_train, history,totalScores = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Try to understand the best parameters for the above model using what we have learned in this lesson (hint: look if the model is overfitting).\n",
    "\n",
    "After the definition of a good model, try to make the prediction over the pred set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Custom model\n",
    "\n",
    "The models that we have built in the previous examples are made using the **Sequantial model**: `from keras.models import Sequential`.\n",
    "\n",
    "The sequential model is the standard to create a network with a sequence of layers,one after the other.\n",
    "\n",
    "Aside from that model, Keras give us the possibility to create networks with others layout ([more info about models](https://keras.io/models/about-keras-models/)).\n",
    "\n",
    "This is done with the **functional API** ([more about functional API](https://keras.io/models/model/)).\n",
    "\n",
    "The functional API usable with this import `from keras.models import Model`.\n",
    "\n",
    "**NOTE:** with this kinf of model we are working directly with tensors ([wiki tensor](https://en.wikipedia.org/wiki/Tensor)). \n",
    "\n",
    "In this case we want to build a model that \"simulate\" a linear regression using a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "\n",
    "inputs = Input(shape=(1,))\n",
    "preds = Dense(1,activation='linear')(inputs)\n",
    "x = np.array([1,2,3,4,5])\n",
    "y = x*2\n",
    "x_test = x*10\n",
    "y_test = x_test*2\n",
    "\n",
    "model = Model(inputs=inputs,outputs=preds)\n",
    "sgd=keras.optimizers.SGD()\n",
    "model.compile(optimizer=sgd ,loss='mse',metrics=['mse'])\n",
    "model.fit(x,y, batch_size=1, epochs=30, shuffle=False)\n",
    "#model.predict(x_test).shape\n",
    "res = pd.DataFrame({'pred':model.predict(x_test)[:,0],'real':y_test})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "type(inputs)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
